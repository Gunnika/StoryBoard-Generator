{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairy_tale the peasants wise daughter\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditi/miniconda3/envs/genai/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "stories = {}\n",
    "source_folder = \"../data/clean_dataset\"\n",
    "\n",
    "dir_paths = []\n",
    "original_stories = []\n",
    "story_names = []\n",
    "story_types = []\n",
    "\n",
    "for dir_name in os.listdir(source_folder):\n",
    "    \n",
    "    if not dir_name.startswith(\".DS_Store\"):\n",
    "        dir_path = os.path.join(source_folder, dir_name)\n",
    "        dir_paths.append(dir_path)\n",
    "        for dir_path in dir_paths:\n",
    "            for story_name in os.listdir(dir_path):\n",
    "                if not story_name.startswith(\".DS_Store\"):\n",
    "                    # print(dir_name, story_name)\n",
    "                    # sys.exit()\n",
    "                    story_types.append(dir_name)\n",
    "                    story_names.append(story_name)\n",
    "                    story_path = os.path.join(dir_path, story_name)\n",
    "                    file_path = story_path + \"/story.txt\"\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        file_content = file.read()\n",
    "                    original_stories.append(file_content)\n",
    "\n",
    "stories[\"original_story\"] = original_stories\n",
    "stories[\"story_name\"] = story_names\n",
    "stories[\"story type\"] = story_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "556it [02:40,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation works 380\n",
      "segmentation doesn't work 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import read_data\n",
    "from segmentation import generateSegments\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import nltk\n",
    "nltk.download('punkt')  # For tokenization\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import TextTilingTokenizer\n",
    "\n",
    "data_folder= \"../data/clean_dataset\"\n",
    "df = read_data(data_folder)\n",
    "\n",
    "df = generateSegments(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 166\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f =0\n",
    "s =0\n",
    "for idx,row in df.iterrows():\n",
    "    if len(row[\"segmented_story\"]) > 0:\n",
    "        if row[\"story_type\"] == \"fairy_tale\":\n",
    "            f+=1\n",
    "        else:\n",
    "            s+=1\n",
    "print(f,s)\n",
    "df.to_csv(\"../data/dataset_info.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate segment wise data for baseline\n",
    "\n",
    "destination_folder = \"../data/baseline0_dataset_segment_wise/\"\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    if len(row[\"segmented_story\"]) > 0:\n",
    "        segments = row[\"segmented_story\"]\n",
    "        for idx, segment in enumerate(segments):\n",
    "            story_type = row[\"story_type\"]\n",
    "            file_name = row[\"story_name\"] + \"_segment_\" + str(idx)\n",
    "            with open(destination_folder+story_type+\"/\"+file_name+\".txt\", \"w\") as file:\n",
    "                file.write(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
